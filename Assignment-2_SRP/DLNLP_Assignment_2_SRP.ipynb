{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqizWm2kTSNy"
      },
      "source": [
        "# Assignment - 2 on BPTT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRq7eYNCTRTe"
      },
      "source": [
        "### Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ofypKp-cTZlx"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n",
        "from tabulate import tabulate\n",
        "from sklearn.model_selection import KFold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0AZpg9GTbl5"
      },
      "source": [
        "### Loading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5CHUVFsqJ3O",
        "outputId": "5e0cee11-cc46-41b5-d041-b0fcf3921f6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train data\n",
            "{'tokens': ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.'], 'chunk_tags': [1, 1, 1, 0, 1, 1, 1, 0, 1], 'pos_tags': [1, 4, 3, 1, 4, 4, 3, 1, 4]}\n",
            "{'tokens': ['Peter', 'Blackburn'], 'chunk_tags': [1, 0], 'pos_tags': [1, 1]}\n",
            "{'tokens': ['BRUSSELS', '1996-08-22'], 'chunk_tags': [1, 0], 'pos_tags': [1, 4]}\n",
            "{'tokens': ['The', 'European', 'Commission', 'said', 'on', 'Thursday', 'it', 'disagreed', 'with', 'German', 'advice', 'to', 'consumers', 'to', 'shun', 'British', 'lamb', 'until', 'scientists', 'determine', 'whether', 'mad', 'cow', 'disease', 'can', 'be', 'transmitted', 'to', 'sheep', '.'], 'chunk_tags': [1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1], 'pos_tags': [2, 1, 1, 4, 4, 1, 4, 4, 4, 3, 1, 4, 1, 4, 4, 3, 1, 4, 1, 4, 4, 3, 1, 1, 4, 4, 4, 4, 1, 4]}\n",
            "{'tokens': ['Germany', \"'s\", 'representative', 'to', 'the', 'European', 'Union', \"'s\", 'veterinary', 'committee', 'Werner', 'Zwingmann', 'said', 'on', 'Wednesday', 'consumers', 'should', 'buy', 'sheepmeat', 'from', 'countries', 'other', 'than', 'Britain', 'until', 'the', 'scientific', 'advice', 'was', 'clearer', '.'], 'chunk_tags': [1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1], 'pos_tags': [1, 4, 1, 4, 2, 1, 1, 4, 3, 1, 1, 1, 4, 4, 1, 1, 4, 4, 1, 4, 1, 3, 4, 1, 4, 2, 3, 1, 4, 3, 4]}\n",
            "Test data\n",
            "{'tokens': ['SOCCER', '-', 'JAPAN', 'GET', 'LUCKY', 'WIN', ',', 'CHINA', 'IN', 'SURPRISE', 'DEFEAT', '.'], 'chunk_tags': [1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1], 'pos_tags': [1, 4, 1, 4, 1, 1, 4, 1, 4, 2, 1, 4]}\n",
            "{'tokens': ['Nadim', 'Ladki'], 'chunk_tags': [1, 0], 'pos_tags': [1, 1]}\n",
            "{'tokens': ['AL-AIN', ',', 'United', 'Arab', 'Emirates', '1996-12-06'], 'chunk_tags': [1, 1, 1, 0, 0, 0], 'pos_tags': [1, 4, 1, 1, 1, 4]}\n",
            "{'tokens': ['Japan', 'began', 'the', 'defence', 'of', 'their', 'Asian', 'Cup', 'title', 'with', 'a', 'lucky', '2-1', 'win', 'against', 'Syria', 'in', 'a', 'Group', 'C', 'championship', 'match', 'on', 'Friday', '.'], 'chunk_tags': [1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1], 'pos_tags': [1, 4, 2, 1, 4, 4, 3, 1, 1, 4, 2, 3, 4, 4, 4, 1, 4, 2, 1, 1, 1, 1, 4, 1, 4]}\n",
            "{'tokens': ['But', 'China', 'saw', 'their', 'luck', 'desert', 'them', 'in', 'the', 'second', 'match', 'of', 'the', 'group', ',', 'crashing', 'to', 'a', 'surprise', '2-0', 'defeat', 'to', 'newcomers', 'Uzbekistan', '.'], 'chunk_tags': [1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1], 'pos_tags': [4, 1, 4, 4, 1, 4, 4, 4, 2, 1, 1, 4, 2, 1, 4, 4, 4, 2, 1, 4, 1, 4, 1, 1, 4]}\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(1)\n",
        "\n",
        "# Load data from JSONL file\n",
        "def load_data(file_path):\n",
        "    data = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            example = json.loads(line)\n",
        "            data.append(example)\n",
        "    return data\n",
        "\n",
        "# Load training and test data\n",
        "train_data = load_data('/content/train.jsonl')\n",
        "\n",
        "# Print a few rows of the training data\n",
        "print(\"Train data\")\n",
        "for i in range(5):\n",
        "    print(train_data[i])\n",
        "\n",
        "# Load training and test data\n",
        "test_data = load_data('/content/test.jsonl')\n",
        "\n",
        "# Print a few rows of the test data\n",
        "print(\"Test data\")\n",
        "for i in range(5):\n",
        "    print(test_data[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ie6ggFAaVjY6"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "q6LAFTWn1XrE"
      },
      "outputs": [],
      "source": [
        "# Function to one-hot encode POS tags with size 5\n",
        "def one_hot_encode_prev(pos_tag):\n",
        "    one_hot = [0, 0, 0, 0, 0]\n",
        "    one_hot[pos_tag] = 1\n",
        "    return one_hot\n",
        "\n",
        "# Function to one-hot encode POS tags with size 4\n",
        "def one_hot_encode_curr(pos_tag):\n",
        "    one_hot = [0, 0, 0, 0]\n",
        "    one_hot[pos_tag - 1] = 1\n",
        "    return one_hot\n",
        "\n",
        "# Function to preprocess the data\n",
        "def preprocess_data(data):\n",
        "    x = []\n",
        "    y = []\n",
        "    for sample in data:\n",
        "        tokens = sample['tokens']\n",
        "        pos_tags = sample['pos_tags']\n",
        "        chunk_tags = sample['chunk_tags']\n",
        "\n",
        "        input_seq = []\n",
        "        target_seq = []\n",
        "\n",
        "        for i in range(len(tokens)):\n",
        "            # One-hot encode previous and current words\n",
        "            prev_word = one_hot_encode_prev(pos_tags[i - 1]) if i > 0 else [1, 0, 0, 0, 0]\n",
        "            current_word = one_hot_encode_curr(pos_tags[i])\n",
        "\n",
        "            # Concatenate previous and current word one-hot encodings\n",
        "            input_seq.append(prev_word + current_word)\n",
        "\n",
        "            # Append chunk tag to target sequence\n",
        "            target_seq.append(chunk_tags[i])\n",
        "\n",
        "        x.append(input_seq)\n",
        "        y.append(target_seq)\n",
        "\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItmQg_9aTh5O"
      },
      "source": [
        "### Single Recurrent Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZK2eS3_UYEKz"
      },
      "outputs": [],
      "source": [
        "class SingleRecurrentPerceptron:\n",
        "    def __init__(self, input_size=9, learning_rate=0.0005):\n",
        "        self.input_size = input_size\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        # Initialize weights and biases\n",
        "        self.W_in = np.random.randn(1, input_size)\n",
        "        self.W_rec = np.random.randn(1, 1)\n",
        "        self.b = np.zeros((1, 1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.prev_hidden = 0  # Initialize previous hidden state\n",
        "        self.hidden_states = []  # Store hidden states\n",
        "        self.hidden_states.append(0)\n",
        "        self.outputs = []  # Store outputs\n",
        "\n",
        "        # Forward pass through the SRP\n",
        "        for t in range(len(x)):\n",
        "            net_input = np.dot(self.W_in, x[t]) + np.dot(self.W_rec, self.prev_hidden) + self.b\n",
        "            hidden_state = self.sigmoid(net_input)\n",
        "            self.hidden_states.append(hidden_state)\n",
        "            self.outputs.append(hidden_state)\n",
        "            self.prev_hidden = hidden_state\n",
        "        return self.outputs\n",
        "\n",
        "    def backward(self, x, y):\n",
        "        # Backpropagation through time\n",
        "        delta_out = [target - output for output, target in zip(self.outputs, y)]\n",
        "\n",
        "        dW_in = np.zeros_like(self.W_in)\n",
        "        dW_rec = np.zeros_like(self.W_rec)\n",
        "        db = np.zeros_like(self.b)\n",
        "\n",
        "        for t in range(len(x)):\n",
        "          delta_hidden = delta_out[t]\n",
        "          dW_rec += delta_hidden * self.hidden_states[t]\n",
        "          dW_in += delta_hidden * x[t].reshape(1, -1)\n",
        "          db += delta_hidden\n",
        "          for i in range(t-1,-1,-1):\n",
        "            delta_hidden *= self.W_rec * self.outputs[i] * (1-self.outputs[i])\n",
        "            dW_rec += delta_hidden * self.hidden_states[i]\n",
        "            dW_in +=  delta_hidden * x[i].reshape(1, -1)\n",
        "            db += delta_hidden\n",
        "\n",
        "        # Update weights\n",
        "        self.W_in += self.learning_rate * dW_in/len(x)\n",
        "        self.W_rec += self.learning_rate * dW_rec/len(x)\n",
        "        self.b += self.learning_rate * db/len(x)\n",
        "\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        # Avoid overflow by clipping large values\n",
        "        x = np.clip(x, -500, 500)\n",
        "        return 1 / (1 + np.exp(-x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "H223puk43UyE"
      },
      "outputs": [],
      "source": [
        "# Function to calculate metrics\n",
        "def calculate_metrics(ground_truth, predictions):\n",
        "    accuracy = accuracy_score(ground_truth, predictions)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(ground_truth, predictions, average='weighted',zero_division=1)\n",
        "    class_wise_precision, class_wise_recall, class_wise_f1, _ = precision_recall_fscore_support(ground_truth, predictions, average=None, zero_division=1)\n",
        "\n",
        "    # Compute class-wise accuracy\n",
        "    class_wise_accuracy = []\n",
        "    for i in range(len(class_wise_precision)):\n",
        "        class_wise_accuracy.append(class_wise_precision[i] * class_wise_recall[i] / class_wise_f1[i] if class_wise_f1[i] != 0 else 0)\n",
        "\n",
        "    return accuracy, precision, recall, f1, class_wise_precision, class_wise_recall, class_wise_f1, class_wise_accuracy\n",
        "\n",
        "def flatten(list_of_lists):\n",
        "    return [item for sublist in list_of_lists for item in sublist]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Apkq1Nvt3txO"
      },
      "outputs": [],
      "source": [
        "# Preprocess training data\n",
        "train_input, train_target = preprocess_data(train_data)\n",
        "\n",
        "# Preprocess test data\n",
        "test_input, test_target = preprocess_data(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "986zg9j0TrJw"
      },
      "source": [
        "# 5-fold cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrIzQz40zaom",
        "outputId": "f19fc81f-f353-4200-81d0-a607550d489a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1:\n",
            "Epoch 1, Average Loss: 0.8995608251799676\n",
            "Epoch 2, Average Loss: 0.8448879515362022\n",
            "Epoch 3, Average Loss: 0.8333566233142405\n",
            "Epoch 4, Average Loss: 0.8309525240551755\n",
            "Fold 2:\n",
            "Epoch 1, Average Loss: 0.878939359458931\n",
            "Epoch 2, Average Loss: 0.8143528293044621\n",
            "Epoch 3, Average Loss: 0.7976440532361837\n",
            "Epoch 4, Average Loss: 0.7933155284051989\n",
            "Fold 3:\n",
            "Epoch 1, Average Loss: 0.7301313131952497\n",
            "Epoch 2, Average Loss: 0.694963467785395\n",
            "Epoch 3, Average Loss: 0.6834476006187388\n",
            "Fold 4:\n",
            "Epoch 1, Average Loss: 0.7438824153888468\n",
            "Epoch 2, Average Loss: 0.7232081934816477\n",
            "Epoch 3, Average Loss: 0.7185729777843893\n",
            "Fold 5:\n",
            "Epoch 1, Average Loss: 0.7268785642741791\n",
            "Epoch 2, Average Loss: 0.7135362978143811\n",
            "Mean Accuracy: 0.8253095372343171\n",
            "Mean Precision: 0.8300079772121418\n",
            "Mean Recall: 0.8253095372343171\n",
            "Mean F1 Score: 0.8173119285176884\n",
            "Accuracies:  [0.8120929766556457, 0.8672761508349438, 0.8672835078659207, 0.8084552685848964, 0.7714397822301787]\n"
          ]
        }
      ],
      "source": [
        "# Initialize lists to store performance metrics across all folds\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "\n",
        "# Define number of folds for cross-validation\n",
        "num_folds = 5\n",
        "kf = KFold(n_splits=num_folds, shuffle=True, random_state=1)\n",
        "\n",
        "# Perform cross-validation\n",
        "for fold_number, (train_index, val_index) in enumerate(kf.split(train_input), 1):\n",
        "    print(f\"Fold {fold_number}:\")\n",
        "    # Initialize the SingleRecurrentPerceptron for this fold\n",
        "    model = SingleRecurrentPerceptron()\n",
        "\n",
        "    # Extract training and validation data for this fold\n",
        "    X_train_fold = [train_input[i] for i in train_index]\n",
        "    X_val_fold = [train_input[i] for i in val_index]\n",
        "    y_train_fold = [train_target[i] for i in train_index]\n",
        "    y_val_fold = [train_target[i] for i in val_index]\n",
        "\n",
        "    # Train the model on the current training fold\n",
        "    num_epochs = 10\n",
        "    prev_loss = 10000     # Arbitrary large\n",
        "    for epoch in range(num_epochs):\n",
        "      total_loss = 0\n",
        "      for i in range(len(X_train_fold)):\n",
        "        x = np.array(X_train_fold[i])\n",
        "        y_true = np.array(y_train_fold[i])\n",
        "\n",
        "        y_pred = np.array(model.forward(x))\n",
        "\n",
        "        # Compute loss\n",
        "        loss = -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "        total_loss += loss\n",
        "\n",
        "        model.backward(x, y_true)\n",
        "\n",
        "      avg_loss = total_loss / len(X_train_fold)\n",
        "      if (avg_loss > prev_loss):\n",
        "        break;\n",
        "      prev_loss = avg_loss\n",
        "      print(f\"Epoch {epoch+1}, Average Loss: {avg_loss}\")\n",
        "\n",
        "    # Validate the model on the current validation fold\n",
        "    ground_truth = flatten(y_val_fold)\n",
        "    predictions = []\n",
        "    threshold = 0.5\n",
        "    for i in range(len(X_val_fold )):\n",
        "        x = np.array(X_val_fold [i])\n",
        "        y_pred = model.forward(x)\n",
        "        y_pred = [1 if value >= threshold else 0 for value in y_pred]\n",
        "        predictions.append(y_pred)\n",
        "\n",
        "    predictions = flatten(predictions)\n",
        "\n",
        "    accuracy, precision, recall, f1, class_wise_precision, class_wise_recall, class_wise_f1, class_wise_accuracy = calculate_metrics(ground_truth, predictions)\n",
        "\n",
        "    # Store performance metrics for this fold\n",
        "    accuracies.append(accuracy)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "# Calculate mean performance metrics across all folds\n",
        "mean_accuracy = np.mean(accuracies)\n",
        "mean_precision = np.mean(precisions)\n",
        "mean_recall = np.mean(recalls)\n",
        "mean_f1_score = np.mean(f1_scores)\n",
        "\n",
        "print(\"Mean Accuracy:\", mean_accuracy)\n",
        "print(\"Mean Precision:\", mean_precision)\n",
        "print(\"Mean Recall:\", mean_recall)\n",
        "print(\"Mean F1 Score:\", mean_f1_score)\n",
        "\n",
        "print(\"Accuracies: \", accuracies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVv_0CdjfvG6"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOp-JEkRd5as",
        "outputId": "34b83af1-2a3c-494a-eae0-5e700ef5794c"
      },
      "outputs": [],
      "source": [
        "best_model = SingleRecurrentPerceptron()\n",
        "num_epochs = 10\n",
        "prev_loss = 10000     # Arbitrary large\n",
        "for epoch in range(num_epochs):\n",
        "  total_loss = 0\n",
        "  for i in range(len(train_input)):\n",
        "    x = np.array(train_input[i])\n",
        "    y_true = np.array(train_target[i])\n",
        "\n",
        "    y_pred = np.array(best_model.forward(x))\n",
        "\n",
        "    # Compute loss\n",
        "    loss = -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "    total_loss += loss\n",
        "\n",
        "    best_model.backward(x, y_true)\n",
        "\n",
        "  avg_loss = total_loss / len(train_input)\n",
        "  if (avg_loss > prev_loss):\n",
        "    break;\n",
        "  prev_loss = avg_loss\n",
        "  print(f\"Epoch {epoch+1}, Average Loss: {avg_loss}\")\n",
        "\n",
        "# Get ground truth from training data\n",
        "ground_truth = flatten(train_target)\n",
        "predictions = []\n",
        "threshold = 0.5\n",
        "for i in range(len(train_input )):\n",
        "    x = np.array(train_input[i])\n",
        "    y_pred = best_model.forward(x)\n",
        "    y_pred = [1 if value >= threshold else 0 for value in y_pred]\n",
        "    predictions.append(y_pred)\n",
        "\n",
        "predictions = flatten(predictions)\n",
        "\n",
        "accuracy, precision, recall, f1, class_wise_precision, class_wise_recall, class_wise_f1, class_wise_accuracy = calculate_metrics(ground_truth, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sSDtRqRkfYs",
        "outputId": "1051d288-1163-4fef-8769-4c7bda059de7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Accuracy: 0.862632046792816\n",
            "Train Precision: 0.8785432111369627\n",
            "Train Recall: 0.862632046792816\n",
            "Train F1 Score: 0.8524650495490824\n",
            "Train Class-wise Accuracy: [0.7836333523196484, 0.9128948051638008]\n",
            "Train Class-wise Precision: [0.9653911 0.8362878]\n",
            "Train Class-wise Recall: [0.60187561 0.98950181]\n",
            "Train Class-wise F1 Score: [0.74147604 0.90646621]\n"
          ]
        }
      ],
      "source": [
        "print(\"Train Accuracy:\", accuracy)\n",
        "print(\"Train Precision:\", precision)\n",
        "print(\"Train Recall:\", recall)\n",
        "print(\"Train F1 Score:\", f1)\n",
        "print(\"Train Class-wise Accuracy:\", class_wise_accuracy)\n",
        "print(\"Train Class-wise Precision:\", class_wise_precision)\n",
        "print(\"Train Class-wise Recall:\", class_wise_recall)\n",
        "print(\"Train Class-wise F1 Score:\", class_wise_f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWWtPFref-Td",
        "outputId": "420a8f48-a052-4143-e695-e965bc4a658e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Weights:\n",
            "W_in: [[ 0.84893976 -0.62494005 -1.33371963 -0.57746627 -0.04825618  0.00992997\n",
            "   0.95409663  0.79556792  0.90009379]]\n",
            "W_rec: [[0.43053134]]\n",
            "b: [[0.01739229]]\n"
          ]
        }
      ],
      "source": [
        "# Print final weights\n",
        "print(\"Final Weights:\")\n",
        "print(\"W_in:\", best_model.W_in)\n",
        "print(\"W_rec:\", best_model.W_rec)\n",
        "print(\"b:\", best_model.b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5qzql9QgB6n"
      },
      "source": [
        "# Testing the model performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CC6sE4b6fAKi",
        "outputId": "6e8accb1-0867-44ec-b974-1d45d127a423"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.8377516959190267\n",
            "Test Precision: 0.861607769021668\n",
            "Test Recall: 0.8377516959190267\n",
            "Test F1 Score: 0.8240459771818623\n",
            "Test Class-wise Accuracy: [0.7599091399147977, 0.897674275261382]\n",
            "Test Class-wise Precision: [0.96613095 0.80572597]\n",
            "Test Class-wise Recall: [0.55368733 0.98962258]\n",
            "Test Class-wise F1 Score: [0.7039453  0.88825606]\n"
          ]
        }
      ],
      "source": [
        "ground_truth = flatten(test_target)\n",
        "predictions = []\n",
        "threshold = 0.5\n",
        "for i in range(len(test_input)):\n",
        "        x = test_input[i]\n",
        "        y_pred = best_model.forward(x)\n",
        "        y_pred = [1 if value > threshold else 0 for value in y_pred]\n",
        "        predictions.append(y_pred)\n",
        "\n",
        "predictions = flatten(predictions)\n",
        "\n",
        "# Calculate metrics for test data\n",
        "test_accuracy, test_precision, test_recall, test_f1, test_class_precision, test_class_recall, test_class_f1,class_wise_accuracy = calculate_metrics(ground_truth, predictions)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "print(\"Test Precision:\", test_precision)\n",
        "print(\"Test Recall:\", test_recall)\n",
        "print(\"Test F1 Score:\", test_f1)\n",
        "print(\"Test Class-wise Accuracy:\", class_wise_accuracy)\n",
        "print(\"Test Class-wise Precision:\", test_class_precision)\n",
        "print(\"Test Class-wise Recall:\", test_class_recall)\n",
        "print(\"Test Class-wise F1 Score:\", test_class_f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blnWt82XznI2"
      },
      "source": [
        "### Language constraints inequalities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_7shempdISe",
        "outputId": "6b3f18d5-e6d8-4606-fe05-4e208bf4c453"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Expression               Boolean Value    Difference\n",
            "---------------------  ---------------  ------------\n",
            "V_cap + WDT > b                      1     1.82043\n",
            "V_cap + WJJ > b                      1     1.6619\n",
            "V_cap + WNN > b                      1     0.876262\n",
            "V_cap + WOT > b                      1     1.76643\n",
            "W_rec + VDT + WJJ < b                1    -0.0902281\n",
            "W_rec + VDT + WNN < b                1    -0.875866\n",
            "VJJ + WJJ < b                        0     0.235494\n",
            "VJJ + WNN < b                        1    -0.550144\n",
            "W_rec + VJJ + WJJ < b                0     0.666025\n",
            "W_rec + VJJ + WNN < b                1    -0.119613\n",
            "VNN + WOT > b                        1     0.292546\n",
            "W_rec + VNN + WOT > b                1     0.723077\n",
            "W_rec + VOT + WDT > b                1     1.35376\n",
            "W_rec + VOT + WJJ > b                1     1.19524\n",
            "W_rec + VOT + WNN > b                1     0.409597\n",
            "W_rec + VOT + WOT > b                1     1.29976\n"
          ]
        }
      ],
      "source": [
        "W_in = np.array(best_model.W_in)\n",
        "W_rec = np.array(best_model.W_rec)\n",
        "b = np.array(best_model.b)\n",
        "\n",
        "# Extracting values from arrays\n",
        "V_cap = W_in[0,0]\n",
        "VNN = W_in[0,1]\n",
        "VDT = W_in[0,2]\n",
        "VJJ = W_in[0,3]\n",
        "VOT = W_in[0,4]\n",
        "WNN = W_in[0,5]\n",
        "WDT = W_in[0,6]\n",
        "WJJ = W_in[0,7]\n",
        "WOT = W_in[0,8]\n",
        "W_rec = W_rec[0,0]\n",
        "b = -b[0,0]\n",
        "\n",
        "inequalities = [\n",
        "    (\"V_cap + WDT > b\", V_cap + WDT > b, V_cap + WDT - b),\n",
        "    (\"V_cap + WJJ > b\", V_cap + WJJ > b, V_cap + WJJ - b),\n",
        "    (\"V_cap + WNN > b\", V_cap + WNN > b, V_cap + WNN - b),\n",
        "    (\"V_cap + WOT > b\", V_cap + WOT > b, V_cap + WOT - b),\n",
        "    (\"W_rec + VDT + WJJ < b\", W_rec + VDT + WJJ < b, (W_rec + VDT + WJJ) - b),\n",
        "    (\"W_rec + VDT + WNN < b\", W_rec + VDT + WNN < b, (W_rec + VDT + WNN) - b),\n",
        "    (\"VJJ + WJJ < b\", VJJ + WJJ < b, VJJ + WJJ - b),\n",
        "    (\"VJJ + WNN < b\", VJJ + WNN < b, VJJ + WNN - b),\n",
        "    (\"W_rec + VJJ + WJJ < b\", W_rec + VJJ + WJJ < b, (W_rec + VJJ + WJJ) - b),\n",
        "    (\"W_rec + VJJ + WNN < b\", W_rec + VJJ + WNN < b, (W_rec + VJJ + WNN) - b),\n",
        "    (\"VNN + WOT > b\", VNN + WOT > b, VNN + WOT - b),\n",
        "    (\"W_rec + VNN + WOT > b\", W_rec + VNN + WOT > b, (W_rec + VNN + WOT) - b),\n",
        "    (\"W_rec + VOT + WDT > b\", W_rec + VOT + WDT > b, (W_rec + VOT + WDT) - b),\n",
        "    (\"W_rec + VOT + WJJ > b\", W_rec + VOT + WJJ > b, (W_rec + VOT + WJJ) - b),\n",
        "    (\"W_rec + VOT + WNN > b\", W_rec + VOT + WNN > b, (W_rec + VOT + WNN) - b),\n",
        "    (\"W_rec + VOT + WOT > b\", W_rec + VOT + WOT > b, (W_rec + VOT + WOT) - b)\n",
        "]\n",
        "\n",
        "# Extracting expressions, boolean values, and results\n",
        "expressions = [inequality[0] for inequality in inequalities]\n",
        "boolean_values = [inequality[1] for inequality in inequalities]\n",
        "results = [inequality[2] for inequality in inequalities]\n",
        "\n",
        "# Creating a table\n",
        "table = zip(expressions, boolean_values, results)\n",
        "print(tabulate(table, headers=[\"Expression\", \"Boolean Value\", \"Difference\"]))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
